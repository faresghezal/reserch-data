{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb03786-6e95-4fee-9939-104c54ffcd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1391756/3833529470.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  staff_flt[\"MTMT\"] = staff_flt[\"MTMT\"].astype(\"int\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "import itertools\n",
    "import warnings\n",
    "import glob\n",
    "import sys\n",
    "staff = pd.read_csv(\"people_flt.csv\")\n",
    "staff_flt = staff[(~staff[\"MTMT\"].isnull()) & (staff[\"MTMT\"]!=11111111) & (staff[\"MTMT\"]!=0) & (staff[\"Munkakör\"].str.lower()!=\"doktorandusz\") & (staff[\"Munkakör\"].str.lower()!=\"sh doktorandusz\")]\n",
    "staff_flt[\"MTMT\"] = staff_flt[\"MTMT\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367af69d-8f1a-4bd4-b3e4-8860490581db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pub_for_author(mtid):\n",
    "    page = 1\n",
    "    size = 1000\n",
    "    tries = 1\n",
    "    author_pubs = []\n",
    "    while True:\n",
    "        os.system(f'wget -O tmp.json \"https://m2.mtmt.hu/api/publication?cond=published;eq;true&cond=core;eq;true&cond=authors.mtid;eq;{mtid}&sort=publishedYear,desc&sort=firstAuthor,asc&size={size}&fields=citations,pubStats&labelLang=hun&page={page}&format=json\" >wget.out 2>wget.err')\n",
    "        with open(\"tmp.json\", \"r\") as f:\n",
    "            try:\n",
    "                dta = json.load(f)\n",
    "                if page == 1 and len(dta[\"content\"]) == 0:\n",
    "                    return []\n",
    "                author_pubs += dta[\"content\"]\n",
    "                if not dta[\"paging\"][\"last\"]:\n",
    "                    page += 1\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                tries += 1\n",
    "                print(\"Error, retrying\")\n",
    "                if tries > 30:\n",
    "                    return []\n",
    "    return author_pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c667f25-1ece-48b2-9724-fd37b658bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 119/119 [00:00<00:00, 33039.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for mtid in tqdm(staff_flt[\"MTMT\"]):\n",
    "    if not os.path.exists(f\"big/{mtid}.json\"):\n",
    "        json.dump(load_pub_for_author(mtid), open(f\"big/{mtid}.json\", \"w\", encoding='utf8'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f74408-2c9f-43e4-9433-b71400512f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifdf = pd.read_csv('./pubgraph/ifdf_v8_2021.csv')\n",
    "ifdf.loc[ifdf[\"if\"].isnull(), \"if\"] = 0.0\n",
    "maxIFYear = ifdf.year.max()\n",
    "ifdf_e = ifdf.copy().set_index([\"year\", \"eissn\"]).sort_index()\n",
    "ifdf_p = ifdf.copy().set_index([\"year\", \"pissn\"]).sort_index()\n",
    "\n",
    "def getif(pub):\n",
    "    if \"journal\" not in pub:\n",
    "        return 0.0, 1.0\n",
    "    year = min(pub[\"publishedYear\"], maxIFYear)\n",
    "    if \"pIssn\" in pub[\"journal\"]:\n",
    "        issn = pub[\"journal\"][\"pIssn\"]\n",
    "        if (year,issn) in ifdf_p.index:\n",
    "            ifval = ifdf_p.loc[(year,issn),\"if\"]\n",
    "            catif = ifdf_p.loc[(year,issn),\"categoryMedianIf\"]\n",
    "            if len(ifval) == 1 and float(ifval) > 0.0:\n",
    "                if len(catif) == 1 and float(catif) > 0.0:\n",
    "                    return float(ifval), float(catif)\n",
    "                else:\n",
    "                    return float(ifval), float(ifval) # ha if-es az újság, de még nem elég régóta. nincs sok ilyen.\n",
    "    if \"eIssn\" in pub[\"journal\"]:\n",
    "        issn = pub[\"journal\"][\"eIssn\"]\n",
    "        if (year,issn) in ifdf_e.index:\n",
    "            ifval = ifdf_e.loc[(year,issn),\"if\"]\n",
    "            catif = ifdf_e.loc[(year,issn),\"categoryMedianIf\"]\n",
    "            if len(ifval) == 1 and float(ifval) > 0.0:\n",
    "                if len(catif) == 1 and float(catif) > 0.0:\n",
    "                    return float(ifval), float(catif)\n",
    "                else:\n",
    "                    return float(ifval), float(ifval) # ha if-es az újság, de még nem elég régóta. nincs sok ilyen.\n",
    "    return 0.0, 1.0\n",
    "\n",
    "# a függvény visszaadja a folyóirat rangját (D1, Q1, Q2, ...)\n",
    "def getrating(pub):\n",
    "    if \"ratings\" not in pub:\n",
    "        return \"\"\n",
    "    for r in pub[\"ratings\"]:\n",
    "        if r[\"otype\"] == \"SjrRating\" and \"ranking\" in r:\n",
    "            return r[\"ranking\"]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def score_person(mtid,auth_year,cit_year):\n",
    "    if not os.path.exists(f'big/{mtid}.json'):\n",
    "        raise Exception(\"Nincs letöltve a publikációs lista!\")\n",
    "    pubs = json.load(open(f'big/{mtid}.json'))\n",
    "    score = score_publist([mtid], pubs,auth_year,cit_year)\n",
    "    score[\"mtid\"] = int(mtid)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def score_publist(mtid_list, pubs,auth_year,cit_year):\n",
    "    score = {\"pub_count\": 0, \"q_paper\": 0, \"q_n_paper\": 0, \"q_book\": 0, \"if\": 0, \"relif\": 0, \"ifcnt\": 0, \"if_norm\": 0, \"relif_norm\": 0, \"h\": 0, \"i\": 0, \"first_pub\": 2100, \"last_pub\": 0}\n",
    "    cit_list = []\n",
    "    useShare = False\n",
    "    ix = 0\n",
    "    for pub in pubs:\n",
    "        if \"publishedYear\" in pub:\n",
    "            if  pub[\"publishedYear\"] >=auth_year:\n",
    "                ix += 1\n",
    "                if \"error\" in pub and pub[\"error\"]!=\"VALIDATION_ERROR\":\n",
    "                    continue\n",
    "                if \"category\" not in pub or pub[\"category\"][\"label\"]!=\"Tudományos\":\n",
    "                    continue\n",
    "                # compute share of the authos\n",
    "                authors = 0\n",
    "                share = len(mtid_list)/len(pub[\"authorships\"]) if len(pub[\"authorships\"])>0 else 0\n",
    "                for a in pub[\"authorships\"]:\n",
    "                    if \"author\" in a and a[\"author\"][\"mtid\"] in mtid_list and a[\"authorTyped\"]:\n",
    "                        authors += 1\n",
    "                if authors < len(mtid_list):\n",
    "                    continue\n",
    "                # compute number of pages\n",
    "                plength = 0\n",
    "                try:\n",
    "                    if \"pageLength\" in pub:\n",
    "                        plength = int(pub[\"pageLength\"])\n",
    "                    elif \"firstPage\" in pub and \"lastPage\" in pub:\n",
    "                        plength = int(pub[\"lastPage\"]) - int(pub[\"firstPage\"]) + 1            \n",
    "                except:\n",
    "                    pass\n",
    "                # compute impact factor\n",
    "                ifct, nrm = getif(pub)        \n",
    "                # compute Q score\n",
    "                if pub[\"otype\"] == \"JournalArticle\" and \"journal\" in pub:\n",
    "                    if \"fullPublication\" in pub and pub[\"fullPublication\"] and \"reviewType\" in pub[\"journal\"] and pub[\"journal\"][\"reviewType\"]==\"REVIEWED\" and \"subType\" in pub and \\\n",
    "                        pub[\"subType\"][\"name\"] in [\"Szakcikk\", \"Összefoglaló cikk\", \"Konferenciaközlemény\", \"Rövid közlemény\", \"Sokszerzős vagy csoportos szerzőségű szakcikk\"]:                \n",
    "                        if ifct > 0:\n",
    "                            totalscr = max(0.6,ifct)\n",
    "                        elif \"foreignEdition\" in pub and pub[\"foreignEdition\"]:\n",
    "                            totalscr = 0.4\n",
    "                        else:\n",
    "                            totalscr = 0.3\n",
    "                        score[\"q_paper\"] += totalscr * share\n",
    "                        score[\"q_n_paper\"] += totalscr * share / nrm if nrm > 0 else totalscr * share\n",
    "                        if ifct > 0:\n",
    "                            score[\"if\"] += ifct\n",
    "                            score[\"relif\"] += totalscr * share\n",
    "                            score[\"ifcnt\"] += 1\n",
    "                            score[\"if_norm\"] += ifct / nrm if nrm > 0 else ifct\n",
    "                            score[\"relif_norm\"] += totalscr * share / nrm if nrm > 0 else totalscr * share\n",
    "                elif \"fullPublication\" in pub and pub[\"fullPublication\"] and \\\n",
    "                    ((pub[\"type\"][\"label\"]==\"Könyvrészlet\" and \"subType\" in pub and pub[\"subType\"][\"label\"]==\"Konferenciaközlemény (Könyvrészlet)\") or pub[\"type\"][\"label\"]==\"Egyéb konferenciaközlemény\"):                \n",
    "                    if plength >= 4:\n",
    "                        totalscr = 0.2 if \"foreignLanguage\" in pub and pub[\"foreignLanguage\"] else 0.1\n",
    "                        score[\"q_paper\"] += totalscr * share\n",
    "                        score[\"q_n_paper\"] += totalscr * share\n",
    "                elif pub[\"type\"][\"label\"] == \"Könyv\" or \\\n",
    "                    (pub[\"type\"][\"label\"] == \"Könyvrészlet\" and \"subType\" in pub and pub[\"subType\"][\"label\"] in [\"Könyvfejezet (Könyvrészlet)\", \"Szaktanulmány (Könyvrészlet)\"]):\n",
    "                    if plength >= 10:\n",
    "                        if plength >= 100:\n",
    "                            totalscr = 2 if \"foreignLanguage\" in pub and pub[\"foreignLanguage\"] else 1\n",
    "                        else:\n",
    "                            totalscr = (0.2 if \"foreignLanguage\" in pub and pub[\"foreignLanguage\"] else 0.1) * math.floor(plength/10)\n",
    "                        score[\"q_book\"] += totalscr * share\n",
    "                # Process citations\n",
    "                independentCitation=0\n",
    "                if \"pubStats\" in pub:\n",
    "                    for a in pub[\"pubStats\"][\"years\"]:\n",
    "                        if a[\"year\"]>=cit_year:\n",
    "                            independentCitation+=a[\"independentCitationCount\"]\n",
    "                if \"independentCitationCount\" in pub:\n",
    "                    score[\"i\"] += independentCitation\n",
    "                    cit_list.append(independentCitation)\n",
    "            \n",
    "            \n",
    "                if \"publishedYear\" in pub:\n",
    "                    score[\"last_pub\"] = max(score[\"last_pub\"], pub[\"publishedYear\"])\n",
    "                    score[\"first_pub\"] = min(score[\"first_pub\"], pub[\"publishedYear\"])\n",
    "                score[\"pub_count\"] += 1\n",
    "    score[\"q\"] = score[\"q_paper\"] + np.minimum(score[\"q_book\"], 3.0)\n",
    "    score[\"qn\"] = score[\"q_n_paper\"] + np.minimum(score[\"q_book\"], 3.0)\n",
    "    # h-index\n",
    "    cit_list.sort(reverse=True)\n",
    "    while score[\"h\"] < len(cit_list) and score[\"h\"] < cit_list[score[\"h\"]]:\n",
    "        score[\"h\"] += 1\n",
    "        \n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_h_score(mtid,auth_year,cit_year):\n",
    "    cit_list = []\n",
    "    if os.path.exists(f'big/{mtid}.json'):\n",
    "        with open(f'big/{mtid}.json') as f:\n",
    "            try:\n",
    "                js = json.load(f)\n",
    "                for pub in js:\n",
    "                    if \"publishedYear\" in pub:\n",
    "                        if  pub[\"publishedYear\"] >=auth_year:\n",
    "                            independentCitation=0\n",
    "                            if \"pubStats\" in pub:\n",
    "                                for a in pub[\"pubStats\"][\"years\"]:\n",
    "                                    if a[\"year\"]>=cit_year:\n",
    "                                        independentCitation+=a[\"independentCitationCount\"]\n",
    "                            cit_list.append(pub[independentCitation])\n",
    "            except:\n",
    "                pass\n",
    "    cit_list.sort(reverse=True)\n",
    "    hindex = 0\n",
    "    while hindex < len(cit_list) and hindex < cit_list[hindex]:\n",
    "        hindex += 1\n",
    "    return hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922795d-b8de-43ea-9638-cc0c39ace181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]/tmp/ipykernel_1391756/243752817.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  staff_flt[\"H index\"] = [0 if np.isnan(mtid) else get_h_score(int(mtid),auth_year,cit_year) for mtid in staff_flt[\"MTMT\"]]\n",
      " 18%|███████▏                                 | 6/34 [41:56<3:09:23, 405.84s/it]"
     ]
    }
   ],
   "source": [
    "dta = {\"MTMT\": [], \"pubCount\": [], \"qScore\": [], \"qnScore\": [], \"ifCount\": [], \"ifScore\": [], \"relifScore\": [], \"ifNormScore\": [], \"relifNormScore\": [], \"citations\": [], \"hIndex\": [], \"firstPub\": [], \"lastPub\": [], \"auth_year\": [], \"cit_year\": []}\n",
    "for auth_year in tqdm(range(1990,2024)):\n",
    "    for cit_year in range(auth_year,2024):\n",
    "        staff_flt[\"H index\"] = [0 if np.isnan(mtid) else get_h_score(int(mtid),auth_year,cit_year) for mtid in staff_flt[\"MTMT\"]]\n",
    "        for idx, prs in staff_flt.iterrows():\n",
    "            scr = score_person(prs[\"MTMT\"],auth_year,cit_year)\n",
    "            dta[\"MTMT\"].append(scr[\"mtid\"])\n",
    "            dta[\"pubCount\"].append(scr[\"pub_count\"])\n",
    "            dta[\"qScore\"].append(scr[\"q\"])\n",
    "            dta[\"qnScore\"].append(scr[\"qn\"])\n",
    "            dta[\"ifCount\"].append(scr[\"ifcnt\"])\n",
    "            dta[\"ifScore\"].append(scr[\"if\"])\n",
    "            dta[\"relifScore\"].append(scr[\"relif\"])\n",
    "            dta[\"ifNormScore\"].append(scr[\"if_norm\"])\n",
    "            dta[\"relifNormScore\"].append(scr[\"relif_norm\"])\n",
    "            dta[\"citations\"].append(scr[\"i\"])\n",
    "            dta[\"hIndex\"].append(scr[\"h\"])\n",
    "            dta[\"firstPub\"].append(scr[\"first_pub\"])\n",
    "            dta[\"lastPub\"].append(scr[\"last_pub\"])\n",
    "            dta[\"auth_year\"].append(auth_year)\n",
    "            dta[\"cit_year\"].append(cit_year)\n",
    "node_person = pd.DataFrame(dta)\n",
    "node_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3451ed-1c1b-4039-9658-aa8516516709",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_no_aff.to_csv(\"big_no aff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a1b82-7622-46d0-ad7b-0fcb8722a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_no_aff.to_csv(\"big_no aff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe79285-455a-4b2c-a080-1ac039d4c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pub_for_author(mtid):\n",
    "    page = 1\n",
    "    size = 1000\n",
    "    tries = 1\n",
    "    author_pubs = []\n",
    "    while True:\n",
    "        os.system(f'wget -O tmp.json \"https://m2.mtmt.hu/api/publication?cond=published;eq;true&cond=institutes;inia;10856&cond=core;eq;true&cond=authors.mtid;eq;{mtid}&sort=publishedYear,desc&sort=firstAuthor,asc&size={size}&fields=citations,pubStats&labelLang=hun&page={page}&format=json\" >wget.out 2>wget.err')\n",
    "        with open(\"tmp.json\", \"r\") as f:\n",
    "            try:\n",
    "                dta = json.load(f)\n",
    "                if page == 1 and len(dta[\"content\"]) == 0:\n",
    "                    return []\n",
    "                author_pubs += dta[\"content\"]\n",
    "                if not dta[\"paging\"][\"last\"]:\n",
    "                    page += 1\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                tries += 1\n",
    "                print(\"Error, retrying\")\n",
    "                if tries > 30:\n",
    "                    return []\n",
    "    return author_pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6b6f5-ce95-4079-abe7-bd7a4b4a1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mtid in tqdm(staff_flt[\"MTMT\"]):\n",
    "    if not os.path.exists(f\"big_ins/{mtid}.json\"):\n",
    "        json.dump(load_pub_for_author(mtid), open(f\"big_ins/{mtid}.json\", \"w\", encoding='utf8'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3e4be-d1e7-442b-959f-6d8fb389dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifdf = pd.read_csv('./pubgraph/ifdf_v8_2021.csv')\n",
    "ifdf.loc[ifdf[\"if\"].isnull(), \"if\"] = 0.0\n",
    "maxIFYear = ifdf.year.max()\n",
    "ifdf_e = ifdf.copy().set_index([\"year\", \"eissn\"]).sort_index()\n",
    "ifdf_p = ifdf.copy().set_index([\"year\", \"pissn\"]).sort_index()\n",
    "\n",
    "def getif(pub):\n",
    "    if \"journal\" not in pub:\n",
    "        return 0.0, 1.0\n",
    "    year = min(pub[\"publishedYear\"], maxIFYear)\n",
    "    if \"pIssn\" in pub[\"journal\"]:\n",
    "        issn = pub[\"journal\"][\"pIssn\"]\n",
    "        if (year,issn) in ifdf_p.index:\n",
    "            ifval = ifdf_p.loc[(year,issn),\"if\"]\n",
    "            catif = ifdf_p.loc[(year,issn),\"categoryMedianIf\"]\n",
    "            if len(ifval) == 1 and float(ifval) > 0.0:\n",
    "                if len(catif) == 1 and float(catif) > 0.0:\n",
    "                    return float(ifval), float(catif)\n",
    "                else:\n",
    "                    return float(ifval), float(ifval) # ha if-es az újság, de még nem elég régóta. nincs sok ilyen.\n",
    "    if \"eIssn\" in pub[\"journal\"]:\n",
    "        issn = pub[\"journal\"][\"eIssn\"]\n",
    "        if (year,issn) in ifdf_e.index:\n",
    "            ifval = ifdf_e.loc[(year,issn),\"if\"]\n",
    "            catif = ifdf_e.loc[(year,issn),\"categoryMedianIf\"]\n",
    "            if len(ifval) == 1 and float(ifval) > 0.0:\n",
    "                if len(catif) == 1 and float(catif) > 0.0:\n",
    "                    return float(ifval), float(catif)\n",
    "                else:\n",
    "                    return float(ifval), float(ifval) # ha if-es az újság, de még nem elég régóta. nincs sok ilyen.\n",
    "    return 0.0, 1.0\n",
    "\n",
    "# a függvény visszaadja a folyóirat rangját (D1, Q1, Q2, ...)\n",
    "def getrating(pub):\n",
    "    if \"ratings\" not in pub:\n",
    "        return \"\"\n",
    "    for r in pub[\"ratings\"]:\n",
    "        if r[\"otype\"] == \"SjrRating\" and \"ranking\" in r:\n",
    "            return r[\"ranking\"]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def score_person(mtid,auth_year,cit_year):\n",
    "    if not os.path.exists(f'big_ins/{mtid}.json'):\n",
    "        raise Exception(\"Nincs letöltve a publikációs lista!\")\n",
    "    pubs = json.load(open(f'big_ins/{mtid}.json'))\n",
    "    score = score_publist([mtid], pubs,auth_year,cit_year)\n",
    "    score[\"mtid\"] = int(mtid)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def score_publist(mtid_list, pubs,auth_year,cit_year):\n",
    "    score = {\"pub_count\": 0, \"q_paper\": 0, \"q_n_paper\": 0, \"q_book\": 0, \"if\": 0, \"relif\": 0, \"ifcnt\": 0, \"if_norm\": 0, \"relif_norm\": 0, \"h\": 0, \"i\": 0, \"first_pub\": 2100, \"last_pub\": 0}\n",
    "    cit_list = []\n",
    "    useShare = False\n",
    "    ix = 0\n",
    "    for pub in pubs:\n",
    "        if \"publishedYear\" in pub:\n",
    "            if  pub[\"publishedYear\"] >=auth_year:\n",
    "                ix += 1\n",
    "                if \"error\" in pub and pub[\"error\"]!=\"VALIDATION_ERROR\":\n",
    "                    continue\n",
    "                if \"category\" not in pub or pub[\"category\"][\"label\"]!=\"Tudományos\":\n",
    "                    continue\n",
    "                # compute share of the authos\n",
    "                authors = 0\n",
    "                share = len(mtid_list)/len(pub[\"authorships\"]) if len(pub[\"authorships\"])>0 else 0\n",
    "                for a in pub[\"authorships\"]:\n",
    "                    if \"author\" in a and a[\"author\"][\"mtid\"] in mtid_list and a[\"authorTyped\"]:\n",
    "                        authors += 1\n",
    "                if authors < len(mtid_list):\n",
    "                    continue\n",
    "                # compute number of pages\n",
    "                plength = 0\n",
    "                try:\n",
    "                    if \"pageLength\" in pub:\n",
    "                        plength = int(pub[\"pageLength\"])\n",
    "                    elif \"firstPage\" in pub and \"lastPage\" in pub:\n",
    "                        plength = int(pub[\"lastPage\"]) - int(pub[\"firstPage\"]) + 1            \n",
    "                except:\n",
    "                    pass\n",
    "                # compute impact factor\n",
    "                ifct, nrm = getif(pub)        \n",
    "                # compute Q score\n",
    "                if pub[\"otype\"] == \"JournalArticle\" and \"journal\" in pub:\n",
    "                    if \"fullPublication\" in pub and pub[\"fullPublication\"] and \"reviewType\" in pub[\"journal\"] and pub[\"journal\"][\"reviewType\"]==\"REVIEWED\" and \"subType\" in pub and \\\n",
    "                        pub[\"subType\"][\"name\"] in [\"Szakcikk\", \"Összefoglaló cikk\", \"Konferenciaközlemény\", \"Rövid közlemény\", \"Sokszerzős vagy csoportos szerzőségű szakcikk\"]:                \n",
    "                        if ifct > 0:\n",
    "                            totalscr = max(0.6,ifct)\n",
    "                        elif \"foreignEdition\" in pub and pub[\"foreignEdition\"]:\n",
    "                            totalscr = 0.4\n",
    "                        else:\n",
    "                            totalscr = 0.3\n",
    "                        score[\"q_paper\"] += totalscr * share\n",
    "                        score[\"q_n_paper\"] += totalscr * share / nrm if nrm > 0 else totalscr * share\n",
    "                        if ifct > 0:\n",
    "                            score[\"if\"] += ifct\n",
    "                            score[\"relif\"] += totalscr * share\n",
    "                            score[\"ifcnt\"] += 1\n",
    "                            score[\"if_norm\"] += ifct / nrm if nrm > 0 else ifct\n",
    "                            score[\"relif_norm\"] += totalscr * share / nrm if nrm > 0 else totalscr * share\n",
    "                elif \"fullPublication\" in pub and pub[\"fullPublication\"] and \\\n",
    "                    ((pub[\"type\"][\"label\"]==\"Könyvrészlet\" and \"subType\" in pub and pub[\"subType\"][\"label\"]==\"Konferenciaközlemény (Könyvrészlet)\") or pub[\"type\"][\"label\"]==\"Egyéb konferenciaközlemény\"):                \n",
    "                    if plength >= 4:\n",
    "                        totalscr = 0.2 if \"foreignLanguage\" in pub and pub[\"foreignLanguage\"] else 0.1\n",
    "                        score[\"q_paper\"] += totalscr * share\n",
    "                        score[\"q_n_paper\"] += totalscr * share\n",
    "                elif pub[\"type\"][\"label\"] == \"Könyv\" or \\\n",
    "                    (pub[\"type\"][\"label\"] == \"Könyvrészlet\" and \"subType\" in pub and pub[\"subType\"][\"label\"] in [\"Könyvfejezet (Könyvrészlet)\", \"Szaktanulmány (Könyvrészlet)\"]):\n",
    "                    if plength >= 10:\n",
    "                        if plength >= 100:\n",
    "                            totalscr = 2 if \"foreignLanguage\" in pub and pub[\"foreignLanguage\"] else 1\n",
    "                        else:\n",
    "                            totalscr = (0.2 if \"foreignLanguage\" in pub and pub[\"foreignLanguage\"] else 0.1) * math.floor(plength/10)\n",
    "                        score[\"q_book\"] += totalscr * share\n",
    "                # Process citations\n",
    "                independentCitation=0\n",
    "                if \"pubStats\" in pub:\n",
    "                    for a in pub[\"pubStats\"][\"years\"]:\n",
    "                        if a[\"year\"]>=cit_year:\n",
    "                            independentCitation+=a[\"independentCitationCount\"]\n",
    "                if \"independentCitationCount\" in pub:\n",
    "                    score[\"i\"] += independentCitation\n",
    "                    cit_list.append(independentCitation)\n",
    "            \n",
    "            \n",
    "                if \"publishedYear\" in pub:\n",
    "                    score[\"last_pub\"] = max(score[\"last_pub\"], pub[\"publishedYear\"])\n",
    "                    score[\"first_pub\"] = min(score[\"first_pub\"], pub[\"publishedYear\"])\n",
    "                score[\"pub_count\"] += 1\n",
    "    score[\"q\"] = score[\"q_paper\"] + np.minimum(score[\"q_book\"], 3.0)\n",
    "    score[\"qn\"] = score[\"q_n_paper\"] + np.minimum(score[\"q_book\"], 3.0)\n",
    "    # h-index\n",
    "    cit_list.sort(reverse=True)\n",
    "    while score[\"h\"] < len(cit_list) and score[\"h\"] < cit_list[score[\"h\"]]:\n",
    "        score[\"h\"] += 1\n",
    "        \n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_h_score(mtid,auth_year,cit_year):\n",
    "    cit_list = []\n",
    "    if os.path.exists(f'big_ins/{mtid}.json'):\n",
    "        with open(f'big_ins/{mtid}.json') as f:\n",
    "            try:\n",
    "                js = json.load(f)\n",
    "                for pub in js:\n",
    "                    if \"publishedYear\" in pub:\n",
    "                        if  pub[\"publishedYear\"] >=auth_year:\n",
    "                            independentCitation=0\n",
    "                            if \"pubStats\" in pub:\n",
    "                                for a in pub[\"pubStats\"][\"years\"]:\n",
    "                                    if a[\"year\"]>=cit_year:\n",
    "                                        independentCitation+=a[\"independentCitationCount\"]\n",
    "                            cit_list.append(pub[independentCitation])\n",
    "            except:\n",
    "                pass\n",
    "    cit_list.sort(reverse=True)\n",
    "    hindex = 0\n",
    "    while hindex < len(cit_list) and hindex < cit_list[hindex]:\n",
    "        hindex += 1\n",
    "    return hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167178e-730a-457a-9c15-3df8ac4f0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta = {\"MTMT\": [], \"pubCount\": [], \"qScore\": [], \"qnScore\": [], \"ifCount\": [], \"ifScore\": [], \"relifScore\": [], \"ifNormScore\": [], \"relifNormScore\": [], \"citations\": [], \"hIndex\": [], \"firstPub\": [], \"lastPub\": [], \"auth_year\": [], \"cit_year\": []}\n",
    "for auth_year in tqdm(range(1990,2024)):\n",
    "    for cit_year in range(auth_year,2024):\n",
    "        staff_flt[\"H index\"] = [0 if np.isnan(mtid) else get_h_score(int(mtid),auth_year,cit_year) for mtid in staff_flt[\"MTMT\"]]\n",
    "        for idx, prs in staff_flt.iterrows():\n",
    "            scr = score_person(prs[\"MTMT\"],auth_year,cit_year)\n",
    "            dta[\"MTMT\"].append(scr[\"mtid\"])\n",
    "            dta[\"pubCount\"].append(scr[\"pub_count\"])\n",
    "            dta[\"qScore\"].append(scr[\"q\"])\n",
    "            dta[\"qnScore\"].append(scr[\"qn\"])\n",
    "            dta[\"ifCount\"].append(scr[\"ifcnt\"])\n",
    "            dta[\"ifScore\"].append(scr[\"if\"])\n",
    "            dta[\"relifScore\"].append(scr[\"relif\"])\n",
    "            dta[\"ifNormScore\"].append(scr[\"if_norm\"])\n",
    "            dta[\"relifNormScore\"].append(scr[\"relif_norm\"])\n",
    "            dta[\"citations\"].append(scr[\"i\"])\n",
    "            dta[\"hIndex\"].append(scr[\"h\"])\n",
    "            dta[\"firstPub\"].append(scr[\"first_pub\"])\n",
    "            dta[\"lastPub\"].append(scr[\"last_pub\"])\n",
    "            dta[\"auth_year\"].append(auth_year)\n",
    "            dta[\"cit_year\"].append(cit_year)\n",
    "node_person = pd.DataFrame(dta)\n",
    "node_person.to_csv(\"big_aff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152a1d6-d336-43a4-b8cd-4d01a98655af",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_person.to_csv(\"big_aff.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba710eba-8268-4080-b42a-341cac197adf",
   "metadata": {},
   "source": [
    "# pub no aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0bdc4-f756-4676-b379-614416d2eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pub_for_author(mtid):\n",
    "    tries = 1\n",
    "    page = 1\n",
    "    while True:\n",
    "        os.system(f'wget -O tmp.json \"https://m2.mtmt.hu/api/publication?cond=authors.mtid;eq;{mtid}&page={page}&fields=citations,pubStats&format=json\" >wget.out 2>wget.err')\n",
    "        with open(\"tmp.json\", \"r\") as f:\n",
    "            try:\n",
    "                dta = json.load(f)\n",
    "                if not os.path.exists(f\"journals3/{mtid}{page}.json\"):\n",
    "                    json.dump(dta, open(f\"journals3/{mtid}{page}.json\", \"w\", encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "                if not dta[\"paging\"][\"last\"]:\n",
    "                    page += 1\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                tries += 1\n",
    "                print(\"Error, retrying\")\n",
    "                if tries > 30:\n",
    "                    return []\n",
    "staff_flt=pd.read_csv('people_flt.csv')\n",
    "for mtid in tqdm(staff_flt[\"MTMT\"]):\n",
    "    load_pub_for_author(mtid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ebd6a4-c97b-48ff-aae5-d3b6b68993f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns =['cit_year','publishedYear','name','authors','independentCitingPubCount','types'])\n",
    "for files in tqdm(os.listdir('journals3/')):\n",
    "    dta = json.load(open(f'journals3/{files}'))\n",
    "    for x in dta[\"content\"]:\n",
    "        for cit_year in range(x[\"publishedYear\"],2024):\n",
    "            auth=\"\"\n",
    "            for y in x[\"authorships\"]:\n",
    "                if \"author\" in y:\n",
    "                    auth=auth+str(y[\"author\"][\"mtid\"])+\",\"\n",
    "            independentCitation=0\n",
    "            if \"pubStats\" in x:\n",
    "                for a in x[\"pubStats\"][\"years\"]:\n",
    "                    if a[\"year\"]>=cit_year:\n",
    "                        independentCitation+=a[\"independentCitationCount\"]\n",
    "            a=pd.Series({'cit_year':cit_year,'publishedYear':x[\"publishedYear\"],'name':x[\"title\"],'authors':auth,'independentCitingPubCount':independentCitation,'types':x[\"otype\"]})\n",
    "            df=pd.concat([df, a.to_frame().T], ignore_index=True)\n",
    "df=df.drop_duplicates(subset=['name','cit_year'])\n",
    "df = df[ (df['types'] != 'Thesis') & (df['types'] != 'Achievement') ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39601d-9275-47e7-96ab-f24d0c1f5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "piub1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f5603-fee6-40f8-9f96-66cf098f34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=piub1['authors'].str.split(',',expand=True)\n",
    "x=x.drop([32], axis=1)\n",
    "x=piub1.join(x)\n",
    "staff_flt[\"MTMT\"] = staff_flt[\"MTMT\"].apply(str)\n",
    "for i in range(32):\n",
    "    mask = x[i].isin(staff_flt[\"MTMT\"])\n",
    "    x[i] = x[i].where(mask, None)\n",
    "for i in range(32):\n",
    "    y=staff_flt\n",
    "    pubs=y.rename(columns={\"MTMT\": i})\n",
    "    x=pd.merge(x, pubs[[i , \"Név\"]], how='left',  on=[i])\n",
    "    x=x.drop([i], axis=1)\n",
    "    x=x.rename(columns={\"Név\": i})\n",
    "x=x.drop([\"authors\"], axis=1)\n",
    "x['authors'] = x[x.columns[5:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "x=x[['cit_year','publishedYear','name','authors','independentCitingPubCount','types']]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907bd0ca-3e78-4533-b838-197929b68e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(\"pub_no_aff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967902ba-41ae-491a-8e6b-e94ed9c89c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pub_for_author(mtid):\n",
    "    tries = 1\n",
    "    page = 1\n",
    "    while True:\n",
    "        os.system(f'wget -O tmp.json \"https://m2.mtmt.hu/api/publication?cond=authors.mtid;eq;{mtid}&cond=institutes;inia;10856&page={page}&fields=citations,pubStats&format=json\" >wget.out 2>wget.err')\n",
    "        with open(\"tmp.json\", \"r\") as f:\n",
    "            try:\n",
    "                dta = json.load(f)\n",
    "                if not os.path.exists(f\"journals2/{mtid}{page}.json\"):\n",
    "                    json.dump(dta, open(f\"journals2/{mtid}{page}.json\", \"w\", encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "                if not dta[\"paging\"][\"last\"]:\n",
    "                    page += 1\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                tries += 1\n",
    "                print(\"Error, retrying\")\n",
    "                if tries > 30:\n",
    "                    return []\n",
    "staff_flt=pd.read_csv('people_flt.csv')\n",
    "for mtid in tqdm(staff_flt[\"MTMT\"]):\n",
    "    load_pub_for_author(mtid)\n",
    "df=pd.DataFrame(columns =['cit_year','publishedYear','name','authors','independentCitingPubCount','types'])\n",
    "for files in tqdm(os.listdir('journals2/')):\n",
    "    dta = json.load(open(f'journals2/{files}'))\n",
    "    for x in dta[\"content\"]:\n",
    "        for cit_year in range(x[\"publishedYear\"],2024):\n",
    "            auth=\"\"\n",
    "            for y in x[\"authorships\"]:\n",
    "                if \"author\" in y:\n",
    "                    auth=auth+str(y[\"author\"][\"mtid\"])+\",\"\n",
    "            independentCitation=0\n",
    "            if \"pubStats\" in x:\n",
    "                for a in x[\"pubStats\"][\"years\"]:\n",
    "                    if a[\"year\"]>=cit_year:\n",
    "                        independentCitation+=a[\"independentCitationCount\"]\n",
    "            a=pd.Series({'cit_year':cit_year,'publishedYear':x[\"publishedYear\"],'name':x[\"title\"],'authors':auth,'independentCitingPubCount':independentCitation,'types':x[\"otype\"]})\n",
    "            df=pd.concat([df, a.to_frame().T], ignore_index=True)\n",
    "df=df.drop_duplicates(subset=['name','cit_year'])\n",
    "df = df[ (df['types'] != 'Thesis') & (df['types'] != 'Achievement') ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68246b61-e606-4442-91b2-72655bf6859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['authors'].str.split(',',expand=True)\n",
    "x=x.drop([32], axis=1)\n",
    "x=df.join(x)\n",
    "staff_flt[\"MTMT\"] = staff_flt[\"MTMT\"].apply(str)\n",
    "for i in range(32):\n",
    "    mask = x[i].isin(staff_flt[\"MTMT\"])\n",
    "    x[i] = x[i].where(mask, None)\n",
    "for i in range(32):\n",
    "    y=staff_flt\n",
    "    pubs=y.rename(columns={\"MTMT\": i})\n",
    "    x=pd.merge(x, pubs[[i , \"Név\"]], how='left',  on=[i])\n",
    "    x=x.drop([i], axis=1)\n",
    "    x=x.rename(columns={\"Név\": i})\n",
    "x=x.drop([\"authors\"], axis=1)\n",
    "x['authors'] = x[x.columns[5:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "x=x[['cit_year','publishedYear','name','authors','independentCitingPubCount','types']]\n",
    "x.to_csv(\"pub_aff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a69eb9-f147-4db2-bf00-a89013407bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
